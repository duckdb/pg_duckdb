-- PostgreSQL instance has data directory set to tmp_check/data so for all read functions argument
-- is relative to that data directory patch
-- read_parquet
SELECT count(r['sepal.length']) FROM read_parquet('../../data/iris.parquet') r;
 count 
-------
   150
(1 row)

SELECT r['sepal.length'] FROM read_parquet('../../data/iris.parquet') r ORDER BY r['sepal.length']  LIMIT 5;
 sepal.length 
--------------
          4.3
          4.4
          4.4
          4.4
          4.5
(5 rows)

SELECT r['sepal.length'], r['file_row_number'], r['filename']
    FROM read_parquet('../../data/iris.parquet', file_row_number => true, filename => true) r
    ORDER BY r['sepal.length']  LIMIT 5;
 sepal.length | file_row_number |        filename         
--------------+-----------------+-------------------------
          4.3 |              13 | ../../data/iris.parquet
          4.4 |               8 | ../../data/iris.parquet
          4.4 |              38 | ../../data/iris.parquet
          4.4 |              42 | ../../data/iris.parquet
          4.5 |              41 | ../../data/iris.parquet
(5 rows)

-- Supports subscripts
SELECT r['jsoncol'][1], r['arraycol'][2] FROM read_parquet('../../data/indexable.parquet') r;
 jsoncol[1] | arraycol[2] 
------------+-------------
 "d"        |          22
(1 row)

-- read_csv
SELECT count(r['sepal.length']) FROM read_csv('../../data/iris.csv') r;
 count 
-------
   150
(1 row)

SELECT r['sepal.length'] FROM read_csv('../../data/iris.csv') r ORDER BY r['sepal.length'] LIMIT 5;
 sepal.length 
--------------
          4.3
          4.4
          4.4
          4.4
          4.5
(5 rows)

SELECT r['sepal.length'], r['filename']
    FROM read_csv('../../data/iris.csv', filename => true, header => true) r
    ORDER BY r['sepal.length']  LIMIT 5;
 sepal.length |      filename       
--------------+---------------------
          4.3 | ../../data/iris.csv
          4.4 | ../../data/iris.csv
          4.4 | ../../data/iris.csv
          4.4 | ../../data/iris.csv
          4.5 | ../../data/iris.csv
(5 rows)

SELECT * FROM read_csv('../../non-existing-file.csv');
ERROR:  (PGDuckDB/CreatePlan) Prepared query returned an error: 'IO Error: No files found that match the pattern "../../non-existing-file.csv"
-- We override Postgres its default column name for subscript expressions. In
-- the following example the column would normally be named "r", which is
-- pretty non-descriptive especially when selecting multiple columns from the
-- same row.
--
-- NOTE: Jelte tried to change this behaviour in upstream Postgres, but met
-- with some resistance:
-- https://www.postgresql.org/message-id/flat/CAGECzQRYAFHLnjjymsSPhL-9OExVyNfMQkZMc1hcoUQ6dDHo=Q@mail.gmail.com
SELECT r['column00'] FROM read_csv('../../data/web_page.csv') r limit 1;
 column00 
----------
        1
(1 row)

-- If an explicit column name is given we
SELECT r['column00'] AS col1 FROM read_csv('../../data/web_page.csv') r limit 1;
 col1 
------
    1
(1 row)

-- ...except if that explicit column name is the same as the default column
-- name. In which case we fail to recognize that fact.
-- XXX: It would be nice to fix this, but it's not a high priority.
SELECT r['column00'] AS r FROM read_csv('../../data/web_page.csv') r limit 1;
 column00 
----------
        1
(1 row)

-- If we use the same trick inside subqueries, then references to columns from
-- that subquery would not use that better name, and thus the query could not
-- be executed. To avoid that we simply don't rename a subscript expression
-- inside a subquery, and only do so in the outermost SELECT list (aka
-- targetlist).
SELECT * FROM (SELECT r['column00'] FROM read_csv('../../data/web_page.csv') r limit 1);
 r 
---
 1
(1 row)

-- If you give it a different alias then that alias is propegated though.
SELECT * FROM (SELECT r['column00'] AS col1 FROM read_csv('../../data/web_page.csv') r limit 1);
 col1 
------
    1
(1 row)

-- Only simple string literals are supported as column names
SELECT r[NULL] FROM read_csv('../../data/web_page.csv') r limit 1;
ERROR:  duckdb.row subscript cannot be NULL
LINE 1: SELECT r[NULL] FROM read_csv('../../data/web_page.csv') r li...
                 ^
SELECT r[123] FROM read_csv('../../data/web_page.csv') r limit 1;
ERROR:  duckdb.row subscript must have text type
LINE 1: SELECT r[123] FROM read_csv('../../data/web_page.csv') r lim...
                 ^
SELECT r[3.14] FROM read_csv('../../data/web_page.csv') r limit 1;
ERROR:  duckdb.row subscript must have text type
LINE 1: SELECT r[3.14] FROM read_csv('../../data/web_page.csv') r li...
                 ^
SELECT r[q.col]
FROM
    read_csv('../../data/web_page.csv') r,
    (SELECT 'abc'::text as col) q
LIMIT 1;
ERROR:  duckdb.row subscript must be a constant
LINE 1: SELECT r[q.col]
                 ^
-- delta_scan
SELECT duckdb.install_extension('delta');
 install_extension 
-------------------
 t
(1 row)

SELECT count(r['a']) FROM delta_scan('../../data/delta_table') r;
 count 
-------
   100
(1 row)

SELECT * FROM delta_scan('../../data/delta_table') r WHERE (r['a'] = 1 OR r['b'] = 'delta_table_3');
 a |       b       
---+---------------
 1 | delta_table_1
 3 | delta_table_3
(2 rows)

-- iceberg_*
SELECT duckdb.install_extension('iceberg');
 install_extension 
-------------------
 t
(1 row)

SELECT COUNT(r['l_orderkey']) FROM iceberg_scan('../../data/lineitem_iceberg', allow_moved_paths => true) r;
 count 
-------
 51793
(1 row)

-- TPCH query #6
SELECT
	sum(r['l_extendedprice'] * r['l_discount']) as revenue
FROM
	iceberg_scan('../../data/lineitem_iceberg', allow_moved_paths => true) r
WHERE
	r['l_shipdate'] >= date '1997-01-01'
	AND r['l_shipdate'] < date '1997-01-01' + interval '1' year
	AND r['l_discount'] between 0.08 - 0.01 and 0.08 + 0.01
	AND r['l_quantity'] < 25
LIMIT 1;
   revenue    
--------------
 1520873.7806
(1 row)

SELECT * FROM iceberg_snapshots('../../data/lineitem_iceberg');
 sequence_number |     snapshot_id     |         timestamp_ms         |                                         manifest_list                                          
-----------------+---------------------+------------------------------+------------------------------------------------------------------------------------------------
               1 | 3776207205136740581 | Wed Feb 15 15:07:54.504 2023 | lineitem_iceberg/metadata/snap-3776207205136740581-1-cf3d0be5-cf70-453d-ad8f-48fdc412e608.avro
               2 | 7635660646343998149 | Wed Feb 15 15:08:14.73 2023  | lineitem_iceberg/metadata/snap-7635660646343998149-1-10eaca8a-1e1c-421e-ad6d-b232e5ee23d3.avro
(2 rows)

SELECT * FROM iceberg_metadata('../../data/lineitem_iceberg',  allow_moved_paths => true);
                             manifest_path                              | manifest_sequence_number | manifest_content | status  | content  |                                     file_path                                      
------------------------------------------------------------------------+--------------------------+------------------+---------+----------+------------------------------------------------------------------------------------
 lineitem_iceberg/metadata/10eaca8a-1e1c-421e-ad6d-b232e5ee23d3-m1.avro |                        2 | DATA             | ADDED   | EXISTING | lineitem_iceberg/data/00041-414-f3c73457-bbd6-4b92-9c15-17b241171b16-00001.parquet
 lineitem_iceberg/metadata/10eaca8a-1e1c-421e-ad6d-b232e5ee23d3-m0.avro |                        2 | DATA             | DELETED | EXISTING | lineitem_iceberg/data/00000-411-0792dcfe-4e25-4ca3-8ada-175286069a47-00001.parquet
(2 rows)

-- read_json
SELECT COUNT(r['a']) FROM read_json('../../data/table.json') r;
 count 
-------
   100
(1 row)

SELECT COUNT(r['a']) FROM read_json('../../data/table.json') r WHERE r['c'] > 50.4;
 count 
-------
    51
(1 row)

SELECT r['a'], r['b'], r['c'] FROM read_json('../../data/table.json') r WHERE r['c'] > 50.4 AND r['c'] < 51.2;
 a  |    b    |  c   
----+---------+------
 50 | json_50 | 50.5
(1 row)

